% Encoding: UTF-8
% Try to keep this list in alphabetical order based on citing name

@article{Colombo2012,
  author    = {Diego Colombo and Marloes H. Maathuis and Markus Kalisch and Thomas S. Richardson},
  title     = {{Learning high-dimensional directed acyclic graphs with latent and selection variables}},
  volume    = {40},
  journal   = {The Annals of Statistics},
  number    = {1},
  publisher = {Institute of Mathematical Statistics},
  pages     = {294 -- 321},
  keywords  = {Causal structure learning, consistency, FCI algorithm, high-dimensionality, maximal ancestral graphs (MAGs), partial ancestral graphs (PAGs), RFCI algorithm, Sparsity},
  year      = {2012},
  doi       = {10.1214/11-AOS940},
  url       = {https://doi.org/10.1214/11-AOS940}
}

@article{Colombo2012_MPC,
  author  = {Colombo, Diego and Maathuis, Marloes},
  year    = {2012},
  month   = {11},
  pages   = {},
  title   = {Order-Independent Constraint-Based Causal Structure Learning},
  volume  = {15},
  journal = {Journal of Machine Learning Research}
}

@article{Gamez2011,
  author  = {Gámez, José and Mateo, Juan and Puerta, Jose},
  year    = {2011},
  month   = {05},
  pages   = {106-148},
  title   = {Learning Bayesian networks by hill climbing: Efficient methods based on progressive restriction of the neighborhood},
  volume  = {22},
  journal = {Data Mining and Knowledge Discovery},
  doi     = {10.1007/s10618-010-0178-6}
}

@article{Jaber2020causal,
  title={Causal discovery from soft interventions with unknown targets: Characterization and learning},
  author={Jaber, Amin and Kocaoglu, Murat and Shanmugam, Karthikeyan and Bareinboim, Elias},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={9551--9561},
  year={2020}
}

@article{Kocaoglu2019characterization,
  title={Characterization and learning of causal graphs with latent variables from soft interventions},
  author={Kocaoglu, Murat and Jaber, Amin and Shanmugam, Karthikeyan and Bareinboim, Elias},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@article{gerhardus2021characterization,
  title   = {Characterization of causal ancestral graphs for time series with latent confounders},
  author  = {Gerhardus, Andreas},
  journal = {arXiv preprint arXiv:2112.08417},
  year    = {2021}
}


@inproceedings{Malinsky18a_svarfci,
  title     = {Causal Structure Learning from Multivariate Time Series in Settings with Unmeasured Confounding},
  author    = {Malinsky, Daniel and Spirtes, Peter},
  booktitle = {Proceedings of 2018 ACM SIGKDD Workshop on Causal Disocvery},
  pages     = {23--47},
  year      = {2018},
  editor    = {Le, Thuc Duy and Zhang, Kun and Kıcıman, Emre and Hyvärinen, Aapo and Liu, Lin},
  volume    = {92},
  series    = {Proceedings of Machine Learning Research},
  month     = {20 Aug},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v92/malinsky18a/malinsky18a.pdf},
  url       = {https://proceedings.mlr.press/v92/malinsky18a.html},
  abstract  = {We present constraint-based and (hybrid) score-based algorithms for causal structure learning that estimate dynamic graphical models from multivariate time series data. In contrast to previous work, our methods allow for both “contemporaneous” causal relations and arbitrary unmeasured (“latent”) processes influencing observed variables. The performance of our algorithms is investigated with simulation experiments and we briefly illustrate the proposed approach on some real data from international political economy.}
}


@article{Meek1995,
  author  = {Meek, Christopher},
  year    = {2013},
  month   = {02},
  pages   = {},
  title   = {Causal Inference and Causal Explanation with Background Knowledge},
  volume  = {2},
  journal = {Proceedings of Eleventh Conference on Uncertainty in Artificial Intelligence, Montreal, QU}
}


@inproceedings{Mooij2020cyclic,
  title     = {Constraint-Based Causal Discovery using Partial Ancestral Graphs in the presence of Cycles},
  author    = {M. Mooij, Joris and Claassen, Tom},
  booktitle = {Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI)},
  pages     = {1159--1168},
  year      = {2020},
  editor    = {Peters, Jonas and Sontag, David},
  volume    = {124},
  series    = {Proceedings of Machine Learning Research},
  month     = {03--06 Aug},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v124/m-mooij20a/m-mooij20a.pdf},
  url       = {https://proceedings.mlr.press/v124/m-mooij20a.html},
  abstract  = {While feedback loops are known to play important roles in many complex systems, their existence is ignored in a large part of the causal discovery literature, as systems are typically assumed to be acyclic from the outset. When applying causal discovery algorithms designed for the acyclic setting on data generated by a system that involves feedback, one would not expect to obtain correct results. In this work, we show that—surprisingly—the output of the Fast Causal Inference (FCI) algorithm is correct if it is applied to observational data generated by a system that involves feedback. More specifically, we prove that for observational data generated by a simple and sigma-faithful Structural Causal Model (SCM), FCI is sound and complete, and can be used to consistently estimate (i) the presence and absence of causal relations, (ii) the presence and absence of direct causal relations, (iii) the absence of confounders, and (iv) the absence of specific cycles in the causal graph of the SCM. We extend these results to constraint-based causal discovery algorithms that exploit certain forms of background knowledge, including the causally sufficient setting (e.g., the PC algorithm) and the Joint Causal Inference setting (e.g., the FCI-JCI algorithm).}
}


@book{Neapolitan2003,
  author    = {Neapolitan, Richard},
  year      = {2003},
  month     = {01},
  pages     = {},
  title     = {Learning Bayesian Networks},
  isbn      = {9780123704771},
  publisher = {Pearson},
  doi       = {10.1145/1327942.1327961}
}

@article{pearl_aspects_1993,
	title = {Aspects of graphical models connected with causality},
	journal = {Proceedings of the 49th Session of the International Statistical Institute},
	author = {Pearl, Judea},
	year = {1993},
	pages = {399--401},
	file = {R195-LL.pdf:/Users/adam2392/Zotero/storage/F5RI5D8V/R195-LL.pdf:application/pdf},
}

@book{Pearl_causality_2009,
  author    = {Pearl, Judea},
  title     = {Causality: Models, Reasoning and Inference},
  year      = {2009},
  isbn      = {052189560X},
  publisher = {Cambridge University Press},
  address   = {USA},
  edition   = {2nd},
  abstract  = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. The book will open the way for including causal analysis in the standard curricula of statistics, artificial intelligence, business, epidemiology, social sciences, and economics. Students in these fields will find natural models, simple inferential procedures, and precise mathematical definitions of causal concepts that traditional texts have evaded or made unduly complicated. The first edition of Causality has led to a paradigmatic change in the way that causality is treated in statistics, philosophy, computer science, social science, and economics. Cited in more than 3,000 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interests to students and professionals in a wide variety of fields. Anyone who wishes to elucidate meaningful relationships from data, predict effects of actions and policies, assess explanations of reported events, or form theories of causal understanding and causal speech will find this book stimulating and invaluable.}
}

@article{pearl1993aspects,
  title     = {Aspects of graphical models connected with causality},
  author    = {Pearl, Judea},
  journal   = {Proceedings of the 49th Session of the International Statistical Institute},
  year      = {1993},
  publisher = {escholarship}
}


@article{pearl2014confounding,
  title     = {Confounding equivalence in causal inference},
  author    = {Pearl, Judea and Paz, Azaria},
  journal   = {Journal of Causal Inference},
  volume    = {2},
  number    = {1},
  pages     = {75--93},
  year      = {2014},
  publisher = {De Gruyter}
}

@article{ramsey2012adjacency,
  title   = {Adjacency-faithfulness and conservative causal inference},
  author  = {Ramsey, Joseph and Zhang, Jiji and Spirtes, Peter L},
  journal = {arXiv preprint arXiv:1206.6843},
  year    = {2012}
}

@article{Runge_pcmci_2019,
  author   = {Jakob Runge  and Peer Nowack  and Marlene Kretschmer  and Seth Flaxman  and Dino Sejdinovic },
  title    = {Detecting and quantifying causal associations in large nonlinear time series datasets},
  journal  = {Science Advances},
  volume   = {5},
  number   = {11},
  pages    = {eaau4996},
  year     = {2019},
  doi      = {10.1126/sciadv.aau4996},
  url      = {https://www.science.org/doi/abs/10.1126/sciadv.aau4996},
  eprint   = {https://www.science.org/doi/pdf/10.1126/sciadv.aau4996},
  abstract = {A novel causal discovery method for estimating nonlinear interdependency networks from large time series datasets. Identifying causal relationships and quantifying their strength from observational time series data are key problems in disciplines dealing with complex dynamical systems such as the Earth system or the human body. Data-driven causal inference in such systems is challenging since datasets are often high dimensional and nonlinear with limited sample sizes. Here, we introduce a novel method that flexibly combines linear or nonlinear conditional independence tests with a causal discovery algorithm to estimate causal networks from large-scale time series datasets. We validate the method on time series of well-understood physical mechanisms in the climate system and the human heart and using large-scale synthetic datasets mimicking the typical properties of real-world data. The experiments demonstrate that our method outperforms state-of-the-art techniques in detection power, which opens up entirely new possibilities to discover and quantify causal networks from time series across a range of research fields.}
}

@inproceedings{Tian1998FindingMD,
  title  = {Finding Minimal D-separators},
  author = {Jing-jing Tian and Azaria Paz},
  year   = {1998}
}

@book{Spirtes1993,
  author    = {Spirtes, Peter and Glymour, Clark and Scheines, Richard},
  year      = {1993},
  month     = {01},
  pages     = {},
  title     = {Causation, Prediction, and Search},
  volume    = {81},
  isbn      = {978-1-4612-7650-0},
  doi       = {10.1007/978-1-4612-2748-9},
  publisher = {The MIT Press}
}


@inproceedings{van-der-zander20a,
  title     = {Finding Minimal d-separators in Linear Time and Applications},
  author    = {van der Zander, Benito and Li\'{s}kiewicz, Maciej},
  booktitle = {Proceedings of The 35th Uncertainty in Artificial Intelligence Conference},
  pages     = {637--647},
  year      = {2020},
  editor    = {Adams, Ryan P. and Gogate, Vibhav},
  volume    = {115},
  series    = {Proceedings of Machine Learning Research},
  month     = {22--25 Jul},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v115/van-der-zander20a/van-der-zander20a.pdf},
  url       = {https://proceedings.mlr.press/v115/van-der-zander20a.html},
  abstract  = {The study of graphical causal models is fundamentally the study of separations and conditional independences. We provide linear time algorithms for two graphical primitives: to test, if a given set is a minimal d-separator, and to find a minimal d-separator in directed acyclic graphs (DAGs), completed partially directed acyclic graphs (CPDAGs) and restricted chain graphs (RCGs) as well as minimal m-separators in ancestral graphs (AGs). These algorithms improve the runtime of the best previously known algorithms for minimal separators  that are based on moralization and thus require quadratic time to construct and handle the moral graph. (Minimal) separating sets have important applications like finding (minimal) covariate adjustment sets or conditional instrumental variables.}
}

@article{Zhang2008,
  title    = {On the completeness of orientation rules for causal discovery in the presence of latent confounders and selection bias},
  journal  = {Artificial Intelligence},
  volume   = {172},
  number   = {16},
  pages    = {1873-1896},
  year     = {2008},
  issn     = {0004-3702},
  doi      = {https://doi.org/10.1016/j.artint.2008.08.001},
  url      = {https://www.sciencedirect.com/science/article/pii/S0004370208001008},
  author   = {Jiji Zhang},
  keywords = {Ancestral graphs, Automated causal discovery, Bayesian networks, Causal models, Markov equivalence, Latent variables},
  abstract = {Causal discovery becomes especially challenging when the possibility of latent confounding and/or selection bias is not assumed away. For this task, ancestral graph models are particularly useful in that they can represent the presence of latent confounding and selection effect, without explicitly invoking unobserved variables. Based on the machinery of ancestral graphs, there is a provably sound causal discovery algorithm, known as the FCI algorithm, that allows the possibility of latent confounders and selection bias. However, the orientation rules used in the algorithm are not complete. In this paper, we provide additional orientation rules, augmented by which the FCI algorithm is shown to be complete, in the sense that it can, under standard assumptions, discover all aspects of the causal structure that are uniquely determined by facts of probabilistic dependence and independence. The result is useful for developing any causal discovery and reasoning system based on ancestral graph models.}
}

@article{Zhang2008AncestralGraphs,
  title = {Causal Reasoning with Ancestral Graphs}
}

@inproceedings{Zhang2011,
  author    = {Zhang, Kun and Peters, Jonas and Janzing, Dominik and Sch\"{o}lkopf, Bernhard},
  title     = {Kernel-Based Conditional Independence Test and Application in Causal Discovery},
  year      = {2011},
  isbn      = {9780974903972},
  publisher = {AUAI Press},
  address   = {Arlington, Virginia, USA},
  abstract  = {Conditional independence testing is an important problem, especially in Bayesian network learning and causal discovery. Due to the curse of dimensionality, testing for conditional independence of continuous variables is particularly challenging. We propose a Kernel-based Conditional Independence test (KCI-test), by constructing an appropriate test statistic and deriving its asymptotic distribution under the null hypothesis of conditional independence. The proposed method is computationally efficient and easy to implement. Experimental results show that it outperforms other methods, especially when the conditioning set is large or the sample size is not very large, in which case other methods encounter difficulties.},
  booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
  pages     = {804–813},
  numpages  = {10},
  location  = {Barcelona, Spain},
  series    = {UAI'11}
}
